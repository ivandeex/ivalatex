%%% page margins
\documentclass[a4paper,12pt,fleqn]{article}
\usepackage[margin=2.5cm]{geometry} % fix page margins

% strengthen samepage because penalties are unreliable
\newenvironment{onsamepage} {\begin{minipage}{\textwidth}} {\end{minipage}}

%%% languages
\usepackage{cmap}					% lookup in pdf
\usepackage{mathtext} 				% cyrillic letters in formulas
\usepackage[T2A]{fontenc}			% encoding
\usepackage[utf8]{inputenc}			% source encoding
\usepackage[english,russian]{babel}	% l18n and hyphenation

%%% mathematics
\usepackage{amsmath,amsfonts,amssymb,mathtools}
\everymath{\displaystyle}

%%% перенос формул по Львовскому
\newcommand*{\hm}[1]{#1\nobreak\discretionary{}{\hbox{$\mathsurround=0pt #1$}}{}}

% totally disable breaking inline formulas across lines
\relpenalty=10000
\binoppenalty=10000

% reduce hyphenation
\lefthyphenmin=8
\righthyphenmin=8

%%% fonts
\usepackage{euscript,mathrsfs,pifont} % euclid font, cool math font, dingbats
\usepackage{tikzsymbols}

%%% figures
\usepackage{graphicx,wrapfig,float}
\numberwithin{figure}{section}
\graphicspath{{images/}}
\newcommand\cfigure[2]{
	\begin{figure}[H] \centering \includegraphics[width=#1]{#2} \end{figure}
}
\newcommand\ccfigure[3]{
	\begin{figure}[H] \centering \includegraphics[width=#1]{#2} \caption{#3} \end{figure}
}

%%% links
\usepackage{color,hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, filecolor=magenta, urlcolor=cyan}

%%% styles
\usepackage{amsthm}

\usepackage{parskip}      % space between paragraphs rather than indentation
\makeatletter             % fix \topsep in amsthm after \usepackage{parskip}
\def\thm@space@setup{\thm@preskip=2.5\parskip \thm@postskip=0pt}
\makeatother

\theoremstyle{definition}
\newtheorem{definition}{Опр-е.}[section]
\newtheorem*{property}{Св-во}   %[definition]
\newtheorem{theorem}{Tеор.}[section]
\newtheorem*{corollary}{След-е} %[theorem]
\newtheorem{lemma}{Лемма}[section]
\newtheorem{problem}{Задача}[section]

% reduce space between theorem and proof
\let\exproof\proof
\def\proof{\vspace{-.6em}\exproof[Док-во]}
\def\solution{\vspace{-.6em}\exproof[Решение]}
%\renewcommand\qedsymbol{$\blacksquare$}

%%% math mode macros
% russian-style greeks
\let\eps\varepsilon
\let\phi\varphi
\let\leqs\leqslant
\let\geqs\geqslant
\let\DS\displaystyle

% math-style capitals
\def\N{\mathbb{N}}
\def\B{\mathbb{B}}
\def\R{\mathbb{R}}
\def\S{\mathfrak{S}}
\def\d{\mathrm{d}}

\def\on{\!:}
\def\mbyn{\dfrac{m}{n}}

\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\corr}{corr}
\DeclareMathOperator{\M}{M}
\DeclareMathOperator{\D}{D}

\newcommand{\mbinom}[2] { \left( \! \middle( \genfrac{}{}{0pt}{}{#1}{#2} \middle) \! \right) }

\usepackage{relsize}  % for \mathlarger
\newcommand{\bigsumunder}[1]{ {\mathlarger\sum_{\mathclap{\substack{#1}}}} }

%%% text mode macros
\def\lets{{\huge$\lrcorner$}\space}
\def\iff{$\;\Longleftrightarrow\;$}
\def\any{$\forall\;$}
\def\todo{\guillemotleft $\mathcal{TODO}$ \guillemotright\textellipsis}
\def\vignette{\vspace{48pt} \noindent \hrulefill~
	          \raisebox{-8pt}[10pt][10pt]{\Huge\ding{102}}
	          ~\hrulefill}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Комбинаторика и Теория Вероятностей}
\author{}
\date{}

\begin{document}

\maketitle
Конспект курсов ``Теория вероятностей -- наука о случайности''
(\href{https://stepik.org/course/2911}{часть I},
\href{https://stepik.org/course/3209}{часть II}).
и ``Современная комбинаторика''
(\href{https://www.coursera.org/learn/modern-combinatorics/home/welcome}{ссылка на курс})
\tableofcontents


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vignette
\section{Комбинаторика}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Основы}

Перестановки (\textit{permutations}): $P_n = n!$

Размещения (\textit{arrangements}) с повторениями:
$\overline{A}_n^{\,k} = n^k$

Размещения (\textit{arrangements}) без повторений:
$A_n^k = (n)_k = n(n-1)...(n-k+1) = \dfrac{n!}{(n-k)!}$

Сочетания (\textit{сombinations}) без повторений:
$C_n^k = \binom{n}{k} = \frac{n!}{k!(n-k)!} = \dfrac{A_n^k}{k!}$

Сочетания (\textit{сombinations}) с повторениями:
$\overline{C}_n^{\,k} = \mbinom{n}{k} = C_{n+k-1}^k$

\medskip
\begin{onsamepage}
	\textit{Задача} \textsuperscript{(\href{https://stepik.org/lesson/47129/step/4}{ссылка})}:
	Подбрасывают 6 правильных костей.
	Найти вероятность, что на них выпало ровно 3 разных значения.
	\begin{solution}
		Всего упорядоченных последовательностей $6^6$.
		Три числа можно выбрать $C_6^3$ способами.
		Используя 3 числа, можно составить $3^6$ последовательностей,
		но среди них будут те, где содержится только 2 числа (их количество равно $3 \cdot (2^6-2)$,
		т.е. 3-мя способами выбираем 2 числа из 3-х и из $2^6$ вариантов убираем 2 последовательности,
		содержащие только 1 число), и те, где содержится только 1 число (3 штуки).
		Искомая вероятность равна $C_6^3(3^6-3(2^6-1))/6^6 \approx 0.23148$
	\end{solution}
\end{onsamepage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Беспорядки}

\href{https://ru.wikipedia.org/wiki/%D0%91%D0%B5%D1%81%D0%BF%D0%BE%D1%80%D1%8F%D0%B4%D0%BE%D0%BA_(%D0%BF%D0%B5%D1%80%D0%B5%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%BA%D0%B0)}{Беспорядок} --- это
перестановка, у которой нет неподвижной точки. Например, письмо не попадает в свой конверт.

Число беспорядков
(\href{https://ru.wikipedia.org/wiki/%D0%A1%D1%83%D0%B1%D1%84%D0%B0%D0%BA%D1%82%D0%BE%D1%80%D0%B8%D0%B0%D0%BB}{субфакториал})
считается по правилу включений-исключений:
\[	!n = n! -\frac{n!}{1!} +\frac{n!}{2!} -\frac{n!}{3!}+\dotsm+(-1)^n\frac{n!}{n!}
       = \sum_{k=0}^n (-1)^k\frac{n!}{k!}	\]
$!n \approx \frac{n!}{e}$ при $n\to\infty$,
поскольку $\sum_{k=0}^{\infty} (-1)^k\frac1k = \frac1e$

\begin{align*}
&	!n = \left\lfloor \frac{n!+1}{e} \right\rfloor \\
& 	!1 = 0		\quad
	!2 = 1		\quad
	!3 = 2		\quad
	!4 = 9		\quad
	!5 = 44		\quad
	!6 = 265
\end{align*}

\medskip
\begin{onsamepage}
\textit{Задача}: Если $n$ писем случайным образом положить
в $n$ конвертов, то какова \textit{вероятность}, что
какое-нибудь из писем попадёт в \textit{свой} конверт?
\begin{solution} $1-\frac{!n}{n!} \approx 1-\frac1e \approx 0.632$ \end{solution}
\end{onsamepage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Комбинаторные тождества}

\begin{align*}
&	C_n^k = C_n^{n-k}	\\
&	C_n^0 C_m^k + C_n^1 C_m^{k-1} + ... + C_n^{k-1} C_m^1 + C_n^k C_m^0 = C_{n+m}^k	\\
&	(C_n^0)^2 + (C_n^1)^2 + ... + (C_n^n)^2 = C_{2n}^n	\\
&	(x+y)^n = \sum_{k=0}^n C_n^k x^k y^{n-k}			\\
&	C_n^0 + C_n^1 + \cdots + C_n^n = \sum_{k=0}^n C_n^k = \mathlarger{2^n}	\\
&	C_n^0 - C_n^1 + \cdots + (-1)^n C_n^n = \sum_{k=0}^n (-1)^k C_n^k
		= \begin{cases*}1, \quad \text{при } n=0		\\
						0, \quad \text{при } n>0	\qquad	(\text{т.к. } (1-1)^n=0)
		  \end{cases*}		\\
&	C_n^0 + C_n^2 + C_n^4 + ... = \mathlarger{2^{n-1}}	\\
&	C_n^1 + C_n^3 + C_n^5 + ... = \mathlarger{2^{n-1}}
\end{align*}
\begin{align*}
&	P(n_1,...,n_k) = \frac{(n_1 + \dots + n_k)!}{n_1! \cdot n_2! \cdots n_k!}	\\
&	(x_1+...+x_k)^n = \bigsumunder{0 \leqs n_i \leqs n \\ n_1+...+n_k=n}
								P(n_1,...,n_k) x_1^{n1} \cdots x_k^{n_k}		\\
&	\mathlarger{k^n} = \bigsumunder{0 \leqs n_i \leqs n \\ n_1+...+n_k=n}
								P(n_1,...,n_k)
\end{align*}

\begin{onsamepage}
\lets $A=\{a_1,...,a_{n+1}\}$ и $V$ -- множество всех $m$-сочетаний с повторениями из $A$. \\
\lets $V_i$ -- такое $m$-сочетание с повторениями из $A$, которое $i$ раз содержит $a_1$.
\begin{align*}
&	|V|=|V_0|+|V_1|+...+|V_m|	\\
&	|V| = \overline{C}_{n+1}^{\,m} = C_{n+m}^m = C_{n+m}^n				\\
&	|V_0| = \overline{C}_n^{\,m} = C_{n+m-1}^{m} = C_{m+n-1}^{n-1}		\\
&	|V_1| = \overline{C}_n^{\,m-1} = C_{n+m-2}^{m-1} = C_{m+n-2}^{n-1}	\\
&	\cdots	\\
&	|V_m| = \overline{C}_n^{\,0} = C_{n+0-1}^0 = C_{n-1}^{n-1}
\end{align*}
Отсюда $C_{m+n}^n = C_{m+n-1}^{n-1} + C_{m+n-2}^{n-1} + ... + C_{n-1}^{n-1}$

\bigskip
При $n=2$
получаем $C_{m+2}^2 = \tfrac{(m+1)(m+1)}{2} = C_{m+1}^1+C_{m+1}^1+...+C_1^1$ \\
$\implies$ $1+2+...+m = \dfrac{m(m+1)}{2}$.

\medskip
При $n=3$
получаем $C_{m+3}^3 = \tfrac{(m+3)(m+2)(m+1)}{6} = C_{m+2}^2+C_{m+1}^2+...+C_2^2$ \\
$\implies$ $1^2+2^2+...+m^2 = \dfrac{m(m+1)(2m+1)}{6}$.
\end{onsamepage}

\bigskip
\begin{onsamepage}
\lets $A=\{a_1,...,a_n\}$ и $V$ -- множество всех $m$-размещений с повторениями из $A$, \\
Тогда $|V| = N = n^m = (n-0)^m C_n^0$, причём $\pmb{m<n}$. \\
\lets свойство $\alpha_i$ -- размещение \textbf{не} содержит $a_i$,
      и наоборот $\alpha'_i$ -- содержит. \\
Имеем $N(\alpha_i)=(n-1)^m$,
      $N(\alpha_i,\alpha_j)=(n-2)^m$, ...,
      $N(\alpha_1,...,\alpha_n)=0$. \\
Поскольку $m<n$, то $N(\alpha'_1,...,\alpha'_n)=0$. \\
По формуле включений-исключений с учётом
	$|V_{\alpha_{i_1},...,\alpha_{i_k}}| = C_n^k$:
\[ n^m C_n^0 - (n-1)^m C_n^1 + (n-2)^m C_n^2
   + ... + (-1)^{n-1} 1^m C_n^{n-1} + (-1)^n 0^m C_n^n = 0 \]
\end{onsamepage}

\medspace
Ещё тождество:
\begin{align*}
&	k \, C_n^k = n \, C_{n-1}^{k-1}		\\
&	1 \, C_n^1 + 2 \, C_n^2 + ... + n \, C_n^n = \sum_{k=1}^n k \, C_n^k = n \, 2^{n-1}
\end{align*}

\begin{onsamepage}
Сколькими способами можно расселить 10 гостей в 4 различных комнатах так,
чтобы ни одна комната не осталась пустой?
\begin{solution}
	По формуле включений-исключений:
	$4^{10} - C_4^1 \cdot 3^{10} + C_4^2 \cdot 2^{10} - C_4^3 \cdot 1^{10}$
\end{solution}
\end{onsamepage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vignette
\section{Вероятность}

\subsection{Условная вероятность}

\begin{onsamepage}
\begin{align*}
&	P(A|B) = \frac{P(A \cap B)}{P(B)}
\\&	P(A_1 \cap ... \cap A_n)
	= P(A_1) \cdot P(A_2|A_1) \cdot P(A_3|A_1 \cap A_2)
	  \cdot ... \cdot P(A_n|A_1 \cap ... \cap A_{n-1})
\end{align*}

Свойства условной вероятности:
\[ P(A \cap B|C) = P(A|C) \cdot P(B|A \cap C) \]
\[ P(A \cap B|A) = P(B|A) \]
\end{onsamepage}

Формула полной вероятности:

\lets $\{H_i\}$ -- разбиение $\Omega = \bigsqcup_{i=1}^n H_i$, т.е.
$\Omega = \bigcup_{i=1}^n H_i$ и $H_i \cap H_j = \varnothing$ при $i \ne j$.
Тогда:
\[ P(B) = \sum_i P(B|H_i) \cdot P(H_i)  \]

Формула Байеса:
\begin{align*}
P(A|B) &= \frac{P(B|A) P(A)}{P(B)} \\
P(H_j|A) &= \frac{P(A|H_j)}{\sum_i P(A|H_i) P(H_i)}
			\qquad \{H_i\} \text{ -- разбиение } \Omega
\end{align*}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vignette
\section{Дискретные СВ}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Дискретные распределения}

Случайная величина -- это функция (отображение) $X\on \Omega\to\R$ \\
Значение случайной велечины -- это число $x\in\R$

Дискретное распределение (PMF, probability mass function): $p_X(x)=P(X=x)$

Дискретная СВ: $p(x_1)=p_1, ..., p(x_n)=p_n$

Условие нормировки: $\sum_i p_i = \sum_i P(X=x_i)=1$

Функция случайной величины $Y=g(X)$:
\[ P(Y=y) = P(g(X)=y) = \sum_{i:\: g(x_i)=y}P(X=x_i) \]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Многомерные дискретные распределения}

Многомерное дискретное распределение $\equiv$ Multivariate discrete distribution

Совместное распределение $X$ и $Y$ (\textit{joint PMF}): $p_{X,Y}(x,y)=P(X=x,Y=y)$

Нормировка совместного распределения:
$\sum_{i,j}p_{ij} = \sum_{i,j} P(X=x_i,Y=y_j) = 1$

Маргинальное распределение:
$p_X(x) = \!\!\sum_{y \in \Omega_Y} p_{X,Y}(x,y)$ \quad
$p_Y(y) = \!\!\sum_{x \in \Omega_X} p_{X,Y}(x,y)$
\cfigure{11cm}{marginal-distribs.png}

$X$, $Y$ независимы: $\forall \; x,y: \; p_{X,Y}(x,y)=p_X(x) \cdot p_Y(y)$


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Условные распределения}

Условное распределение $X$ при условии, что событие $A$ наступило:
\[ p_{X|A}(x)=P(X=x|A)=\dfrac{P(X=x,A)}{P(A)} \qquad P(A) \ne 0 \]

Условное распределение $X$ при условии, что $Y=y$:
\begin{align*}
&	A=\{Y=y\}	\qquad p_Y(y)>0 \\
&	p_{X|Y}(x|y) = P(X=x\,|\,Y=y) = \dfrac{P(X=x,Y=y)}{P(Y=y)} = \dfrac{p_{X,Y}(x,y)}{p_Y(y)} \\
&	\forall y \quad \sum_k p_{X|Y}(x_k|y)=1		\qquad \text{(условие нормировки)}
\end{align*}

Формула умножения
\begin{align*}
&	p_{X,Y}(x,y) = p_{X|Y}(x|y) p_Y(y) = p_{Y|X}(y|x) p_X(x)
\end{align*}

Формула умножения для трёх СВ:
\begin{align*}
&	P(A \cap B \cap C) = P(A) P(B|A) P(C|A \cap B) \\
&	p_{X,Y,Z}(x,y,z) = P(X=x, Y=y, Z=z) \\
&	p_{X,Y,Z}(x,y,z) = p_X(x) p_{Y|X}(y|x) p_{Z|X,Y}(z|x,y) \\
&	p_{Z|X,Y}(z|x,y) = P(Z=z|X=x,Y=y) = \frac{p_{X,Y,Z}(x,y,z)}{p_{X,Y}(x,y)}
\end{align*}

$X,Y,Z$ --- независимы, если $\forall x,y,z \quad p_{X,Y,Z}(x,y,z) = p_X(x)p_Y(y)p_Z(z)$


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Моменты случайной величины. Матожидание}

Матожидание $\M(X) = E(X) = \sum_i x_i p_i$
\quad $\exists$ if сходится абсолютно $\sum_i |x_i|p_i < \infty$

Если $Y=g(X)$,
то $\M(Y)=\sum y_i \, p_Y(y_i) = \sum g(x_i) \, p_X(x_i)$

Если $Z=\phi(X,Y)$,
то $\M(Z) = \sum_i z_i \, p_Z(z_i) = \sum_{i,j} \phi(x_i,y_j) \, p_{X,Y}(x_i,y_j)$

\begin{align*}
&	\M(X^k) = \sum_i x_i^k p_X(x_i) &&\text{--- $k$-й начальный момент} \\
&	\M[X-M(X)]^k 	&&\text{--- $k$-й центральный момент}
\end{align*}

\begin{onsamepage}
Свойства мат. ожидания:
\begin{enumerate}
	\item линейность: $\M(aX+bY) = a\M(X)+b\M(Y)$
	\item если $X$ и $Y$ независимы, то $\M(X\cdot Y) = \M(X)\cdot \M(Y)$
\end{enumerate}
\end{onsamepage}

\bigskip
Условное среднее:
\[	\M(X|A) = \sum_i x_i \, p_{X|A}(x_i)
	\quad\text{или}\quad
	\M(X|Y=y) = \sum_i x_i \, p_{X|Y}(x_i|y) \]

Формула полной вероятности:
\[ \M(X) = \sum_i \M(X|H_i) \, P(H_i)  \]


\begin{lemma}
	Если $X\on x_k=k ,\; k=0,1,2,... ,\; P(X=k)=p_k$,
	то $\; \M(X)=\sum_{k=0}^{\infty}P(X>k)$
\end{lemma}
\begin{proof}
\begin{align*}
&	P(X>k) = P(X=k+1) + P(X=k+2) + ... = \sum_{i=k+1}^{\infty}p_i \\
&	\sum_{k=0}^{\infty}P(X>k) =
	\sum_{k=0}^{\infty} \sum_{i=k+1}^{\infty}p_i
	\; \overset{\Winkey}{=} \;
	\sum_{i=1}^{\infty} \sum_{k=0}^{i-1} p_i =
	\sum_{i=1}^{\infty} i \cdot p_i =
	\sum_{i=0}^{\infty} i \cdot p_i = \M(X)
\end{align*}
\end{proof}

\bigskip
\begin{onsamepage}
\textit{Задача} \textsuperscript{(\href{https://stepik.org/lesson/47129/step/13}{ссылка})}:
По каналу связи передается либо бесконечная последовательность ``0'' с вероятностью $\tfrac23$,
либо ``1'' -- с вероятностью $\tfrac13$. Каждый символ, независимо от других,
воспринимается приемником с ошибкой (т.е. вместо ``1'' принимается ``0'' и наоборот)
с вероятностью $0.25$. Найти среднее значение номера первой принятой ``1''.
\begin{solution} ~\\
Если передаются ``1'', то $P(Rcv_1|Snd_1)=0.75$ и $\M(Pos_1|Snd_1)=\tfrac1p=4/3$. \\
Если передаются ``0'', то $P(Rcv_1|Snd_0)=0.25$ и $\M(Pos_1|Snd_0)=\tfrac1p=4$. \\
По формуле полной вероятности: \\
$ \M(Pos_1) = \M(Pos_1|Snd_1) \cdot P(Snd_1) + \M(Pos_1|Snd_0) \cdot P(Snd_0)
			= \tfrac43 \!\cdot\! \tfrac13 + 4 \!\cdot\! \tfrac23 = \tfrac{28}{9} $.
\end{solution}
\end{onsamepage}

\bigskip
\begin{onsamepage}
\textit{Задача}: \lets $X,Y \sim Geom(p)$ -- независимые СВ. Найти $\M(X|X+Y=c)$.
\begin{solution}
\begin{align*}
&	P(X+Y=c) = P_{Pascal}(m=2,p,k=c) = C_{k-1}^{m-1} p^m q^{k-m} = (c-1)p^2q^{c-2} \\
&	P(X|X+Y=c) = \frac{P(X=k)P(Y=c-k)}{P(X+Y=c)} = \frac{pq^{k-1} pq^{c-k-1}}{(c-1)p^2q^{c-2}} = \frac{1}{c-1}
\end{align*}
То есть: $Z=\{X|X+Y=c\}$ -- равномерно распределённая на $k=\overline{1,c-1}$ случайная величина.
Отсюда: $\M(X|X+Y=c) = \M(Z) = \frac{1}{c-1}\cdot\frac{1+2+...+(c-1)}{2} = \frac{c}{2}$.
\end{solution}
\end{onsamepage}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Дисперсия}

\begin{align*}
&	\D(X) = \var(X) = \M(X-\M X)^2 = \M(X^2) - (\M X)^2 \geqs 0 \\
&	\D(c) = 0 \\
&	\D(cX) = c^2\D(X)
\end{align*}

Среднее квадратическое отклонение (standard deviation):
$\sigma(X) = \sqrt{\D(X)}$

$X$ и $Y$ независимы $implies$ $\D(X+Y) = \D(X) + \D(Y)$

В общем случае  $\D(X+Y) = \D(X) + \D(Y) + 2\cov(X,Y)$

Ковариация  $\cov(X,Y) = \M[(X-\M X)(Y-\M Y)] = \M(XY)-\M(X)\M(Y)$

$X$ и $Y$ независимы $\implies$ $\cov(X,Y)=0$ (но не наоборот)

Коэффициент корреляции (correlation)
$r = \rho = \corr(X,Y) = \frac{\cov(X,Y)}{\sigma(X) \cdot \sigma(Y)} $

Свойства корреляции:
\begin{itemize}
	\item $-1 \leqs \rho \leqs 1$
	\item $X$, $Y$ -- независимы $\implies$ $\rho=0$
	\item $Y=aX+c$, $a>0$ $\implies$ $\rho=1$
	\item $Y=aX+c$, $a<0$ $\implies$ $\rho=-1$
\end{itemize}

Размерность:
$X$(кг) $\D_X$(кг${}^2$) $\sigma_X$(кг)
$Y$(см) $\cov_{X,Y}$(кг$\cdot$см) $\rho_{X,Y}$(``1'')


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Задача о беспорядках}

\lets $n$ писем случайно разбрасываются по $n$ конвертам.

Число комбинаций, когда ни одно письмо не попадёт в свой конверт $!n$. \\
Вероятность, что ни одно письмо не попадёт в свой конверт $\frac{!n}{n!}$

\lets $X$ - число писем, попавших в свой конверт. $X = \sum_k I_{A_k}$. \\
$I_{A_k}$ -- индикаторная СВ,
$A_k$ -- событие ``письмо $k$ попало в свой конверт''.
\begin{align*}
&	\M(I_{A_k}) = P(A_k) = \frac{1}{n}	\qquad	\M(I_{A_k}^2) = \frac{1}{n} \\
&	\M(I_{A_k} \cdot I_{A_m}) = P(A_k \cap A_m) = \frac{1}{n(n-1)}
\end{align*}
\begin{onsamepage}
Тогда:
\begin{align*}
\M(X) &= n \M(I_{A_k}) = 1		\\
\D(X) &= \sum_k \D(I_{A_k}) + 2 \sum_{k>m} \cov(I_{A_k},I_{A_m}) = \\
	  &=   \sum_k \left( \M(I_{A_k}^2) - \M^2(I_{A_k}) \right)
	 	 +2\sum_{k>m} \big( \M(I_{A_k} I_{A_m}) - \M(I_{A_k}) \M(I_{A_m}) \big) = \\
	  &= n \left( \frac{1}{n} - \frac{1}{n^2} \right)
	     + 2\, \frac{n(n-1)}{2} \left( \frac{1}{n(n-1)} - \frac{1}{n^2} \right) = \\
	  &= 1
\end{align*}
\end{onsamepage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Простые распределения}


Индикаторная СВ:
\begin{align*}
&	I_A(\omega) = \begin{cases*}
			1, \qquad \omega \in A	\\
			0, \qquad \omega \notin A
		\end{cases*}	\\
&	p(I_A=1) = p_A		\\
&	\M(I_A) = p_A	\qquad	\M(I_A^2) = p_A  \\
&	\D(I_A) = p_A - p_A^2	\\
&	\M(I_A I_B) = \M(I_{A \cap B}) = P(A \cap B)
\end{align*}

Распределение Бернулли (Bernoulli distribution):
\begin{align*}
&	P(X=1)=p \quad P(X=0)=q \quad p\in[0,1] \quad q=1-p \\
&	\M(X) = p \\
&	\D(X) = pq
\end{align*}

\medskip
Равномерное дискретное распределение (Discrete uniform distribution):
\begin{align*}
&	P(X=x_k)=\dfrac{1}{N} \quad k=\overline{1,N} \\
&	\M(X) = \frac{1}{n} \sum_{i=1}^n x_i \\
&	\D(X) = 
\end{align*}

\medskip
\begin{onsamepage}
Гипергеометрическое распределение (Hypergeometric distribution):
\begin{align*}
&	P(X=r) = \dfrac{C_M^r C_N^{n-r}}{C_{M+N}^n} \qquad r = 0,...,\min(M,n)
\end{align*}
Урна: $M$ белых + $N$ чёрных шаров. Вынимаем $n$ шаров. \\
	  $R$ -- число вынутых белых шаров.
\end{onsamepage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Биномиальное распределение (Binomial distribution)}

Схема испытаний Бернулли:
$A_1,...,A_n \quad P(A_i)=p \quad p\in[0,1] \quad q=1-p$

Биномиальное распределение:
\[ X \sim binomial(n,p) \quad P(X=k)=C_n^k p^k q^{n-k}
   \quad k=\overline{0,n} \quad p\in[0,1] \quad q=1-p \]
$k$ -- число успехов в схеме из $n$ испытаний Бернулли.

Условие нормировки: $\DS \sum_{k=0}^n{P(k)} = \sum_{k=0}^n{C_n^k p^k q^{n-k}} = 1$

С ростом числа опытов график уплотняется вокруг точки $np$.

Симметрично при $p=0.5$, скошено влево при $p<0.5$.

Можно представить как сумму НОР СВ Бернулли:
\[ X_{binomial} = X_1 + ... + X_n \]
Следовательно, среднее $\M = np$ и дисперсия $\D = npq$

Из чего можно получить красивое равенство:
\[ \sum_{k=0}^n k C_n^k p^k q^{n-k} = np \]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Геометрическое распределение (Geometric distribution)}

\[ X \sim Geom(p) \quad P(X=k)=pq^{k-1} \quad
k\in\N \quad p\in[0,1] \quad q=1-p \]
$k$ -- номер первого успеха в схеме Бернулли, т. е. до него в $k-1$ опыте были неудачи
(схема Бернулли --- ряд \textit{независимых} опытов)

Свойство: $P(X>n) = q^n$, т. к. $X>n$ \iff $n$ опытов окончились неудачей:
  \[ P(X=\overline{n+1,\infty}) = \sum_{k=n}^{\infty}pq^k
       = pq^n \sum_{k=0}^{\infty} q^k = pq^n\frac1{1-q} = pq^n\frac1p \]

Успех наступил в 1-м опыте: $P(X=1) = p$

Успех в 1-м опыте не наступил: $P(X>1) = q$

Отсутствие памяти (memoryless):
\[ P(X=m+n \;|\, X>m) = \dfrac{P(X=m+n)}{P(X>m)}
   = \dfrac{pq^{m+n-1}}{q^m} = pq^{n-1} = P(X=n) \]
Геометрическое --- единственное среди дискретных распределение с таким свойством.

\begin{onsamepage}
Следствия из свойства отсутствия памяти:
\begin{align*}
&	P(X=1+n|X>1) = P(X=1+n)  \qquad \implies \\
&	\M(X|X>1) = \M(X+1) = \M(X)+1  \\
&	\M(X^2|X>1) = \M\left( (X+1)^2 \right)
\end{align*}
\end{onsamepage}

\begin{onsamepage}
Мат. ожидание $M_{geom}(X) = \frac1p$
{\par\centering\it число.опытов.до.первого.успеха $\times$ вероятность.успеха = \rm1 \par}
\begin{proof}
\begin{align*}
 \M(X) &= \M(X|X=1) P(X=1) + \M(X|X>1) P(X>1) \\
	   &= 1\cdot p + (1+\M(x))q = 1 + q \M(X)
\end{align*}
\end{proof}
Отсюда $\sum_{k=0}^{\infty}kq^k = \frac1{p^2}$
\end{onsamepage}

\[ \D(X)=\frac{q}{p^2} \]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Распределение Паскаля (Negative binomial)}

\begin{onsamepage}
\begin{align*}
&	Z \sim Pascal(m,p) \qquad P(Z=k)=C_{k-1}^{m-1} p^m q^{k-m} \\
&	p\in[0,1] \quad q=1-p  \qquad  k \geqs m \quad k,m\in\N
\end{align*}
$k$ -- номер опыта, на котором произошёл $m$-й успех в схеме Бернулли

\medskip
\def\kh{\kappa}
\def\mh{m}
Выводится так:
\begin{align*}
P_{Pascal}(Z=\kh;m=\mh) &= P_{binomial}(X=\mh-1; n=\kh-1) \cdot p		\\
						&= p \cdot C_{\kh-1}^{\mh-1} p^{\mh-1} q^{(\kh-1)-(\mh-1)}
						= C_{\kh-1}^{\mh-1} p^{\mh} q^{\kh-\mh}
\end{align*}
\end{onsamepage}

$Z \sim Pascal(m,p)$ можно представить (в силу отсутствия памяти у $Geom$)
как сумму $m$ независимых одинаково распределённых (НОР) СВ:
		$Z=X_1+...+X_m$, где $X_i \sim Geom(p)$.
Отсюда получаем \mbox{мат. ожидание} и дисперсию:  % \mbox prevents hypenation
\[	\M(Z) = \frac{m}{p}	\qquad	\D(Z) = \frac{m q}{p^2} \]

\hangindent=6.2em \hangafter=1
\textbf{Замечание}: Часто под распределением ``Negative binomial''
подразумевается число \textbf{неудач} до наступления $m$-го успеха:
$\M_\text{неудач} = \M(Z)-m$.


\subsection{Сумма случайного числа НОР случайных величин}

\begin{onsamepage}
\lets $Z=\sum_{k=1}^N X_k$,
	причём $\M(X_k)=\M_X$, $\D(X_k)=D_X$, $\M(N)=\M_N$, $\D(N)=\D_N$. \\
Тогда $\M(Z) = \M_X \M_N$, $\D(Z) = \D_X \M_N + \M_X^2 \D_N$.
\begin{proof} ~\\
\lets $P_N(N=n) = P_n$, $\M(X^2) = \M_{X^2}$, $\M(Z) = \M_Z$.
\begin{align*}
	\M(Z) &= \sum_i \M(Z|H_i) P(H_i) = \sum_n \M(Z|N=n) P(N=n) = \\
	      &= \sum_n \sum_{k=1}^n \M(X_k) P_n = \sum_n P_n n \M_X = \M_N \M_X
\end{align*}
\begin{align*}
	\D(Z) &= \M(Z^2) - \M^2(Z) = \sum_n \M(Z^2|N=n) P(N=n) - \M_Z^2 = \\
		  &= \sum_n \M \left( \sum_{k=1}^n X_k \right)^2 P_n - \M_Z^2 =
	         \sum_n P_n \left( \sum_{i=1}^nX_i \right) \left( \sum_{j=1}^nX_j \right) - \M_Z^2 = \\
		  &= \sum_n P_n \sum_{i=1}^n X_i^2 + \sum_n P_n 2 \sum_{i < j}^n X_i X_j - \M_Z^2 = \\
	      &= \sum_n P_n n \M(X^2) + \sum_n P_n 2 \frac{n(n-1)}{2} \M(X) \M(X) - \M_Z^2 = \\
	      &= \M_{X^2} \M_N + \sum_n P_n n^2 \M_X^2 - \sum_n P_n n \M_X^2 - \M_N^2 \M_X^2 = \\
	      &= \M_N \M_{X^2} - \M_N \M_X^2 + \M(N^2) \M_X^2 - \M_N^2 \M_X^2 = \M_N \D_X + \D_N \M_X^2
\end{align*}
\end{proof}
\end{onsamepage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Распределение Пуассона (Poisson distribution)}

Является приближением последовательности биномиальных распределений:
\begin{align*}
&	S_n=binomial(n,p_n) \text{ при } n\to\infty ,\; p_n\to0 ,\; np_n\to\lambda
\;\implies\; P(S_n=k)\to \dfrac{e^{-\lambda}\lambda^k}{k!}		\\
&	X \sim Poisson(\lambda): P(X=k) = \dfrac{e^{-\lambda}\lambda^k}{k!}
\quad \lambda>0 \quad k=0,1,2,...		\\
&	\M(X) = \D(X) = \frac{1}{\lambda}
\end{align*}
Симметрично при $\lambda \approx 10$, скошено влево при $\lambda<10$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vignette
\section{Непрерывные СВ}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Вероятностное пространство}

\begin{onsamepage}
\begin{definition}[$\sigma$-алгебра]
\textit{$\sigma$-алгебра над множеством $X$}
--- это семейство $\S$ подмножеств множества $X$, т.ч.:
\begin{enumerate}
	\item $X \in \S$ и $\varnothing \in \S$
	\item если $E \in \S$, то $X \setminus E \in \S$
	\item если $\exists$ семейство $\{A_n\} \in \S$ (конечное или счётное),
	      то $\DS \bigcup_{n=1}^{\infty} A_n \in \S$
	      и $\DS \bigcap_{n=1}^{\infty} A_n \in \S$
\end{enumerate}
\end{definition}
\end{onsamepage}

\begin{definition}[Борелевское множество]
	\textit{$\B$-множество} --- такое множество, которое может быть
	получено из \textit{открытых или замкнутых промежутков} на $\R$
	конечным или счетным числом операций $\bigcup A_n$ и $\bigcap A_n$.
\end{definition}

\begin{definition}
	\textit{Борелевская $\sigma$-алгебра} $\equiv$ минимальная
	$\sigma$-алгебра борелевских множеств на $\R$.
\end{definition}


\medskip
\begin{problem}
	Является ли множество всех рациональных точек на прямой борелевским,
	т.е. верно ли, что
	$\left\{ \mbyn, n=1,2,...; m=0,1,2,... \right\} \in \B$?
\end{problem}
\begin{solution}
	{\bfseries Да.}\\
	Каждую точку можно рассматривать как отрезок
	$\left[ \mbyn,\mbyn \right] =
	\left( -\infty, \mbyn \right] \setminus \left( -\infty, \mbyn \right)$,
	причём множество всех рациональных точек на прямой счетно.
\end{solution}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Функции распределения и плотности}

Функция распределения вероятности (CDF)
\begin{enumerate}
	\item $F_X(x) = P(X \leqs x)$
	\item $0\leqs F_X \leqs 1$
	\item $F$ -- монотонно неубывающая
	\item $F(-\infty)=0$, $F(+\infty)=1$
	\item $P(a< X \leqs b) = F(b)-F(a)$
	\item $F$ -- непрерывна \textit{справа}
	\item $F$ -- это некоторая вероятность, т.е. безразмерная величина
\end{enumerate}

Замечание: если бы CDF была определена как
$P(X {\pmb{\textcolor{red}<}} x)$,
то была бы непрерывна \textit{слева}.

\cfigure{11cm}{cdf-example-big.png}

\cfigure{6cm}{cdf-example-small.jpg}

Функция плотности распределения (PDF):
\begin{enumerate}
	\item $f(u) \geqs 0$
	\item $f(x)=F'(x)=\dfrac{dF(x)}{dx}$
	\item $\DS P(X\leqs x)=F(x)=\int_{-\infty}^{x}f(u)du$
	\item $\DS \int_{-\infty}^{+\infty}f(u)du=1$ -- условие нормировки
	\item $P(X=a)=0$
	\item $P(X \in \left<x,x+\delta\right>) \approx f(x) \delta$
	\item размерность $f$ есть $\dfrac{1}{\text{размерность}(X)}$
		  (например, $\text{см}^{-1}$, $\text{кг}^{-1}$)
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Характеристики непрерывных СВ}

\begin{onsamepage}
Матожидание $\M(x)=\int_{-\infty}^{+\infty}uf(u)du$

$\M(x)$ существует \iff интеграл сходится \textit{абсолютно}:
$\int_{-\infty}^{+\infty}|u|f(u)du < \infty$.
\end{onsamepage}

Матожидание может не существовать.
Пример -- распределение Коши: $f(x)=\dfrac{1/\pi}{1+x^2}$.
Для него $\DS \int_{-\infty}^{+\infty}|u|f(u)du
            = \frac2\pi \int_0^\infty \frac{x\,\mathrm{d}x}{1+x^2}
            = \frac1\pi \ln(1+x^2) \Big\rvert_0^\infty \to \infty$

Если $f(x)=f(-x)$ (чётная), то $\M(X)=0$ (если существует).

\medskip

Матожидание функции
$\M\left( \phi(x) \right) = \int_{-\infty}^{+\infty}\phi(u) f(u) \d u$.

\medskip

Дисперсия $\D(X) = \M\left( X-\M(X) \right) = \M(X^2)-\M^2(X)$

\bigskip

Медиана (характеристика \textit{положения}):
$\mathrm{Me}(X) = arg \left\{ F_X(x) = 1/2 \right\}$

Медиана существует \textit{всегда}.

Если $f(x)=f(-x)$ (чётная), то для нормировки функции плотности имеем:
\[ 1 = \int_{-\infty}^\infty f(u)du
     = \int_{-\infty}^0 f(u)du + \int_0^\infty f(u)du
     = F(0) + \int_\infty^0 f(-u)d(-u) = F(0) + F(0) \]
а значит $F(0)=1/2$, т.е. $\mathrm{Me}(X) = 0$.

\bigskip

Нижний квартиль: $F(Q_1) = 1/4$

Нижний квартиль: $F(Q_3) = 3/4$

Межквартильный размах: $IQR=Q_3-Q_1$

\medskip

Квантиль уровня $\alpha$: $F(q_{\alpha})=\alpha$

Квантильная функция $Q(p)=F^{-1}(x)$, $p\!\in\![0,1]$ --
функция, обратная к функции распределения


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Экспоненциальное распределение}

\cfigure{.9\linewidth}{exp-dist.png}

$X \sim Exp(\lambda)$

PDF: $\DS f(u) = \lambda e^{-\lambda u}$, $u\geqs0$, $\lambda>0$

CDF: $\DS F(X) = P(X\leqs x) = \int_0^x \lambda e^{-\lambda u} du = 1-e^{-\lambda x}$

\begin{align*}
	   f(u)&=\lambda e^{-\lambda u} \qquad u\geqs 0 ,\; \lambda>0
	\\ F(x)&=1-e^{-\lambda x} \qquad x\geqs 0
	\\ \M(x)&=\frac{1}{\lambda}
	\\ \D(x)&=\frac{1}{\lambda^2}
	\\ \mathrm{Me}(x)&=\frac{\ln 2}{\lambda} \qquad \text{скошено вправо: } Me<M
\end{align*}

Свойство отсутствия памяти:
\[ P(X>t+s|X>t) = \frac{P(X>t+s,X>t)}{P(X>t)} = \frac{P(X>t+s)}{P(X>t)} =
   \frac{e^{-\lambda(t+s)}}{e^{-\lambda t}}=P(X>s) \quad (s,t\!\geqs\!0) \]

Среди дискретных распределений свойством отсутствия памяти обладает геометрическое.
Экспоненциальное распределение -- непрерывный аналог геометрического.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Процесс Пуассона}

\textit{Случайный процесс} -- последовательость случайных величин в дискретном времени
(обычно НОР, т.е. независимых одинаково распределённых).


Пуассоновский процесс -- непрерывный аналог процесса Бернулли:
	\[ P(k,t) = \frac{(\lambda t)^k}{k!} e^{-\lambda t} \]


Свойства ПП:
\begin{enumerate}
	\item стационарный (распределение числа событий зависит только от длины интервала)
	\item ординарный (вряд ли на очень малом интервале произойдёт больше одного события)
	\item поток с отсутствием памяти.
\end{enumerate}


\begin{problem}
	Будет ли пуассоновский процесс подходящей моделью процесса
	прибытия пассажиров в пункт выдачи багажа в аэропорту?
\end{problem}
\begin{solution}
  \textbf{Нет.}\\
	Не выполняется требование независимости событий, т.к.
	пассажиры приходят за багажом после посадки самолета и, если мы наблюдаем,
	к примеру, что в зону получения багажа за последнюю минуту пришли 15 человек,
	то следует ожидать значительное количество людей в течение следующей минуты.
	Как получают багаж? Сначала толпа, потом редкие одиночки.
\end{solution}


\begin{onsamepage}
\begin{problem}
	Будет ли пуассоновский процесс подходящей моделью процесса поступления
	звонков в регистратуру поликлиники в течение рабочего дня?
\end{problem}
\begin{solution}
  \textbf{Нет.}\\
	Не выполняется требование стационарности пуассоновского процесса, т.к.
	частота звонков намного выше в утренние часы в сравнении с вечерними.
	К концу дня поток звонков при любом распорядке будет снижаться
	(если это не ночной стационар).
\end{solution}
\end{onsamepage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Прочие распределения}

Равномерное распределение $X \sim Uniform(a,b)$:
\begin{align*}
	   F(x) &=
	   		\begin{cases}
	   			0	& x<a \\
		   		\dfrac{x-a}{b-a}	& a \leqs x \leqs b \\
		   		1	& x>b
			\end{cases}
	\\ f(x) &= \begin{cases}
				0		& x<a \\
				1/(b-a)	& a \leqs x \leqs b \\
				0		& x>b
			\end{cases}
	\\ Me = M &= (a+b)/2
	\\ D &= (b-a)^2/12
\end{align*}


Распределение Лапласа:
\begin{align*}
	   f &= \frac{\lambda}2 e^{-\lambda|x|}
	\\ M &= 0
	\\ D &= \frac{2}{\lambda^2}
\end{align*}


Распределение Коши:
\begin{align*}
	   f(x)=\dfrac{1/\pi}{1+x^2}
\end{align*}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vignette
\section{Вспомогательные формулы}

\begin{align*}
	   \int_0^\infty     e^{-ax}dx &= \frac{1}{a}
	\\ \int_0^\infty x   e^{-ax}dx &= \frac{1}{a^2}
	\\ \int_0^\infty x^2 e^{-ax}dx &= \frac{2}{a^3}
	\\ \int_0^\infty x^n e^{-ax}dx &= \frac{n!}{a^{n+1}}
\end{align*}
\begin{align*}
	   a^3-b^3 &= (a-b)(a^2+ab+b^2)
	\\ (a-b)^3 &= a^3-3a^2b+3ab^2-b^3
\end{align*}
\begin{align*}
&	\sum_{k=0}^n k C_n^k p^k q^{n-k} = np \\
&	\sum_{k=0}^{\infty}kq^k = \frac{1}{p^2} \\
&	\sum_{i=0}^{\infty}\sum_{j=i+1}^{\infty}a_{ij} =
	\sum_{j=1}^{\infty}\sum_{i=0}^{j-1}a_{ij} \\
&	\sum_{n=1}^{\infty}\frac{n}{2^n} = 2
\end{align*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vignette
\end{document}
